(window.webpackJsonp=window.webpackJsonp||[]).push([[151],{579:function(e,a,t){"use strict";t.r(a);var s=t(15),n=Object(s.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("blockquote",[t("p",[e._v("最近准备入手大数据开发了，不知道从何入手，网上找了很多关于大数据的学习路线，基本都大同小异来来回回就那些东西，万事开头难啊，在此笔者总结了大数据最基本的学习技术栈。大数据的5V特点：VOLUME（大量）、VELOCITY（高速）、VARIETY（多样）、VALUE（低价值密度）、VERACITY（真实性）。")])]),e._v(" "),t("p",[e._v("下面是我画的大数据开发学习路线图，希望对你有帮助：")]),e._v(" "),t("iframe",{attrs:{src:e.$withBase("/markmap/大数据学习路线图.html"),width:"100%",height:"400",frameborder:"0",scrolling:"No",leftmargin:"0",topmargin:"0"}}),e._v(" "),t("h3",{attrs:{id:"大数据生态"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大数据生态"}},[e._v("#")]),e._v(" 大数据生态")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/1700062-04eb1d4be6fcde42.png",alt:""}})]),e._v(" "),t("p",[e._v("下面自底向上介绍各个层的主要项目。")]),e._v(" "),t("h4",{attrs:{id:"_1-采集层和传输层"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-采集层和传输层"}},[e._v("#")]),e._v(" 1 采集层和传输层")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/1700062-eee620e1dfdfe4b5.png",alt:""}})]),e._v(" "),t("ul",[t("li",[e._v("Sqoop")])]),e._v(" "),t("p",[e._v("在hadoop和关系型数据库之间转换数据。")]),e._v(" "),t("ul",[t("li",[e._v("Flume")])]),e._v(" "),t("p",[e._v("Flume是一个分布式的高可用的数据收集、聚集和移动的工具。通常用于从其他系统搜集数据，如web服务器产生的日志，通过Flume将日志写入到Hadoop的HDFS中。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/1700062-e7852b900003ddcc.png",alt:""}})]),e._v(" "),t("ul",[t("li",[e._v("Canal")])]),e._v(" "),t("p",[e._v("数据抽取是 ETL 流程的第一步。我们会将数据从 RDBMS 或日志服务器等外部系统抽取至数据仓库，进行清洗、转换、聚合等操作。在现代网站技术栈中，MySQL 是最常见的数据库管理系统，我们会从多个不同的 MySQL 实例中抽取数据，存入一个中心节点，或直接进入 Hive。市面上已有多种成熟的、基于 SQL 查询的抽取软件，如著名的开源项目 Apache Sqoop，然而这些工具并不支持实时的数据抽取。MySQL Binlog 则是一种实时的数据流，用于主从节点之间的数据复制，我们可以利用它来进行数据抽取。借助阿里巴巴开源的 Canal 项目，我们能够非常便捷地将 MySQL 中的数据抽取到任意目标存储中。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/1700062-9209e20afbc97475.png",alt:""}})]),e._v(" "),t("ul",[t("li",[e._v("Logstash")])]),e._v(" "),t("p",[e._v("Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的 “存储库” 中。")]),e._v(" "),t("ul",[t("li",[e._v("Kafka")])]),e._v(" "),t("p",[e._v("消息队列，一个分布式流平台。")]),e._v(" "),t("ul",[t("li",[e._v("RocketMQ")])]),e._v(" "),t("p",[e._v("阿里巴巴开源的消息队列。")]),e._v(" "),t("h4",{attrs:{id:"_2-存储层"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-存储层"}},[e._v("#")]),e._v(" 2 存储层")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/1700062-276b8bc154190f9c.png",alt:""}})]),e._v(" "),t("ul",[t("li",[e._v("HBase")])]),e._v(" "),t("blockquote",[t("p",[e._v("HBase is the Hadoop database, a distributed, scalable, big data store.")])]),e._v(" "),t("ul",[t("li",[e._v("Alluxio/Redis/Ignite")])]),e._v(" "),t("p",[e._v("Alluxio以内存为中心分布式存储系统，从下图可以看出， Alluxio主要有两大功能，第一提供一个文件系统层的抽象，统一文件系统接口，桥接储存系统和计算框架；第二通过内存实现对远程数据的加速访问。详情参考"),t("a",{attrs:{href:"https://docs.alluxio.io/os/user/1.6/en/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Alluxio document"),t("OutboundLink")],1),e._v("。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/1700062-9a2d24c5a3b6a15e.png",alt:""}})]),e._v(" "),t("p",[t("strong",[e._v("Redis")]),e._v("是一个开源的内存键值数据库，相比于Memcache，支持丰富的数据结构。")]),e._v(" "),t("p",[t("strong",[e._v("Ignit")]),e._v("是一个以内存为中心的分布式数据库，缓存和处理平台，用于事务，分析和流式工作负载，在PB级别的数据上提供接近内存速度访问数据。")]),e._v(" "),t("p",[e._v("从上述分析可知，Alluxio/Redis/Ignite主要都是通过内存来实现加速。")]),e._v(" "),t("ul",[t("li",[e._v("TiDB")])]),e._v(" "),t("p",[e._v("TiDB是有PingCap开源的分布式NewSQL关系型数据库。NewSQL数据库有两个流派，分别是以Google为代表的Spanner/F1和以Amazon 为代表的Aurora(极光)，目前国内做NewSQL数据库主要是参考Google的Spanner架构，Google Spanner也是未来NewSQL的发展趋势。")]),e._v(" "),t("ul",[t("li",[e._v("HDFS")])]),e._v(" "),t("p",[e._v("Hadoop的分布式文件系统。")]),e._v(" "),t("ul",[t("li",[e._v("Ceph")])]),e._v(" "),t("p",[e._v("Linux中备受关注的开源分布式存储系统，除了GlusterFS，当属Ceph。目前Ceph已经成为RedHat旗下重要的分布式存储产品，并继续开源。Ceph提供了块储存RDB、分布式文件储存Ceph FS、以及分布式对象存储Radosgw三大储存功能，是目前为数不多的集各种存储能力于一身的开源存储中间件。")]),e._v(" "),t("ul",[t("li",[e._v("Kudu")])]),e._v(" "),t("p",[e._v("Kudu是cloudera开源的运行在hadoop平台上的列式存储系统,拥有Hadoop生态系统应用的常见技术特性，运行在一般的商用硬件上，支持水平扩展,高可用，目前是Apache Hadoop生态圈的新成员之一（incubating）。")]),e._v(" "),t("p",[e._v("Kudu的设计与众不同,它定位于应对快速变化数据的快速分析型数据仓库，希望靠系统自身能力，支撑起同时需要高吞吐率的顺序和随机读写的应用场景，提供一个介于HDFS和HBase的性能特点之间的一个系统，在随机读写和批量扫描之间找到一个平衡点，并保障稳定可预测的响应延迟。可与MapReduce, Spark和其它hadoop生态系统集成。")]),e._v(" "),t("h4",{attrs:{id:"_3-计算层"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-计算层"}},[e._v("#")]),e._v(" 3 计算层")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/1700062-e1ee93ea0e44094b.png",alt:""}})]),e._v(" "),t("ul",[t("li",[e._v("Hive")])]),e._v(" "),t("p",[e._v("Facebook 开源。Hive是一个构建在Hadoop上的数据仓库框架。Hive的设计目标是让精通SQL技能但Java编程技能相对较弱的分析师能对存放在Hadoop上的大规数据执行查询。\nHive的查询语言HiveQL是基于SQL的。任何熟悉SQL的人都可以轻松使用HiveSQL写查询。和RDBMS相同，Hive要求所有数据必须存储在表中，而表必须有模式（Schema），且模式由Hive进行管理。")]),e._v(" "),t("p",[e._v("类似Hive的同类产品：kylin druid SparkSQL Impala。")]),e._v(" "),t("p",[e._v("KylinApache Kylin™是一个开源的分布式分析引擎，提供Hadoop/Spark之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由eBay Inc. 开发并贡献至开源社区。它能在亚秒内查询巨大的Hive表。")]),e._v(" "),t("p",[t("strong",[e._v("Druid")]),e._v(" 为监控而生的数据库连接池。")]),e._v(" "),t("p",[t("code",[e._v("SparkSQL,Spark SQL is Apache Spark's module for working with structured data.")])]),e._v(" "),t("p",[t("strong",[e._v("Impala")]),e._v(",Impala是Apache Hadoop的开源，本地分析数据库。 它由Cloudera，MapR，Oracle和Amazon等供应商提供。")]),e._v(" "),t("ul",[t("li",[e._v("Spark")])]),e._v(" "),t("p",[e._v("Spark是一个分布式计算框架。")]),e._v(" "),t("ul",[t("li",[e._v("Storm")])]),e._v(" "),t("p",[e._v("Storm是一个分布式的、高容错的实时计算系统。Storm对于实时计算的的意义相当于Hadoop对于批处理的意义。Hadoop为我们提供了Map和Reduce原语，使我们对数据进行批处理变的非常的简单和优美。同样，Storm也对数据的实时计算提供了简单Spout和Bolt原语。")]),e._v(" "),t("p",[e._v("Storm适用的场景：①、流数据处理：Storm可以用来用来处理源源不断的消息，并将处理之后的结果保存到持久化介质中。②、分布式RPC：由于Storm的处理组件都是分布式的，而且处理延迟都极低，所以可以Storm可以做为一个通用的分布式RPC框架来使用。")]),e._v(" "),t("ul",[t("li",[e._v("Flink")])]),e._v(" "),t("blockquote",[t("p",[e._v("Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale.")])]),e._v(" "),t("p",[e._v("百度翻译：apacheflink是一个框架和分布式处理引擎，用于在无界和有界数据流上进行有状态计算。Flink被设计成在所有常见的集群环境中运行，以内存速度和任何规模执行计算。")]),e._v(" "),t("ul",[t("li",[e._v("TensorFlow")])]),e._v(" "),t("blockquote",[t("p",[e._v("TensorFlow™ is an open source software library for high performance numerical computation. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs, GPUs, TPUs), and from desktops to clusters of servers to mobile and edge devices. Originally developed by researchers and engineers from the Google Brain team within Google’s AI organization, it comes with strong support for machine learning and deep learning and the flexible numerical computation core is used across many other scientific domains.")])]),e._v(" "),t("p",[e._v("百度翻译：\nTensorFlow™ 是一个用于高性能数值计算的开源软件库。其灵活的体系结构允许跨各种平台（CPU、GPU、TPU）轻松部署计算，从台式机到服务器集群，再到移动和边缘设备。最初是由谷歌人工智能组织内谷歌大脑团队的研究人员和工程师开发的，它对机器学习和深度学习有着强大的支持，灵活的数值计算核心被用于许多其他科学领域。")]),e._v(" "),t("ul",[t("li",[e._v("分布式资源调度")])]),e._v(" "),t("p",[t("strong",[e._v("YARN")]),e._v(", Apache YARN(Yet Another Resource Negotiator)是hadoop的集群资源管理系统。YARN在Hadoop2时被引入，最初是为了改善MapReduce的实现，但它具有足够的通用性，也支持其他的分布式计算模式。")]),e._v(" "),t("ul",[t("li",[e._v("Mesos")])]),e._v(" "),t("p",[e._v("Mesos 最初由 UC Berkeley 的 AMP 实验室于 2009 年发起，遵循 Apache 协议，目前已经成立了 Mesosphere 公司进行运营。Mesos 可以将整个数据中心的资源（包括 CPU、内存、存储、网络等）进行抽象和调度，使得多个应用同时运行在集群中分享资源，并无需关心资源的物理分布情况。")]),e._v(" "),t("p",[e._v("如果把数据中心中的集群资源看做一台服务器，那么 Mesos 要做的事情，其实就是今天操作系统内核的职责：抽象资源 + 调度任务。Mesos 项目是 Mesosphere 公司 Datacenter Operating System (DCOS) 产品的核心部件。")]),e._v(" "),t("ul",[t("li",[e._v("Kubernetes")])]),e._v(" "),t("p",[e._v("Kubernetes是Google 2014年推出的开源容器集群管理系统，基于Docker构建一个容器调度服务，为容器化的应用提供资源调度、部署运行、均衡容灾、服务注册、扩容缩容等功能。")]),e._v(" "),t("ul",[t("li",[e._v("Presto")])]),e._v(" "),t("p",[e._v("Presto是FaceBook开源的一个开源项目。Presto被设计为数据仓库和数据分析产品：数据分析、大规模数据聚集和生成报表。这些工作经常通常被认为是线上分析处理操作。\nPresto通过使用分布式查询，可以快速高效的完成海量数据的查询。如果你需要处理TB或者PB级别的数据，那么你可能更希望借助于Hadoop和HDFS来完成这些数据的处理。作为Hive和Pig（Hive和Pig都是通过MapReduce的管道流来完成HDFS数据的查询）的替代者，Presto不仅可以访问HDFS，也可以操作不同的数据源，包括：RDBMS和其他的数据源（例如：Cassandra）。")]),e._v(" "),t("ul",[t("li",[e._v("其他（区块链框架）")])]),e._v(" "),t("p",[t("strong",[e._v("Etherenum")]),e._v("， 以太坊\n"),t("strong",[e._v("HyperLedger")]),e._v("，超级账本")]),e._v(" "),t("h4",{attrs:{id:"_4-工具层和服务层"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-工具层和服务层"}},[e._v("#")]),e._v(" 4 工具层和服务层")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/1700062-20640cb0fbf4fa06.png",alt:""}})]),e._v(" "),t("ul",[t("li",[e._v("Zeppelin")])]),e._v(" "),t("p",[e._v("Web-based notebook that enables data-driven,interactive data analytics and collaborative documents with SQL, Scala and more.")]),e._v(" "),t("p",[e._v("百度翻译：基于Web的笔记本，支持数据驱动、交互式数据分析和SQL、Scala等协作文档。")]),e._v(" "),t("ul",[t("li",[e._v("Kylin")])]),e._v(" "),t("p",[e._v("Apache Kylin™是一个开源的分布式分析引擎，提供Hadoop/Spark之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由eBay Inc. 开发并贡献至开源社区。它能在亚秒内查询巨大的Hive表。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/Ezuy-Lee/RainzeDrawingBed/media/1700062-ad29ed5daf3be13b.png",alt:""}})]),e._v(" "),t("ul",[t("li",[e._v("Jupyter")])]),e._v(" "),t("blockquote",[t("p",[e._v("The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.")])]),e._v(" "),t("p",[e._v("百度翻译：Jupyter笔记本是一个开源的web应用程序，允许您创建和共享包含实时代码、公式、可视化和叙述文本的文档。用途包括：数据清洗和转换、数值模拟、统计建模、数据可视化、机器学习等。")]),e._v(" "),t("h4",{attrs:{id:"大数据处理工具"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大数据处理工具"}},[e._v("#")]),e._v(" 大数据处理工具")]),e._v(" "),t("p",[e._v("详见这篇文章。\n"),t("a",{attrs:{href:"https://www.jianshu.com/p/72bbd29a3aee",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://www.jianshu.com/p/72bbd29a3aee"),t("OutboundLink")],1)]),e._v(" "),t("h3",{attrs:{id:"大数据环境搭建"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大数据环境搭建"}},[e._v("#")]),e._v(" 大数据环境搭建")]),e._v(" "),t("p",[e._v("笔者也搭建了一套大数据开发环境服务，基于docker镜像搭建，主要组件有：\nHadoop、\nSpark、\nHive (on Tez)、\nTez、\nHue、\nFlink、\nZookeeper、\nKafka、\nMySQL等，具体在GitHub拉取源码。"),t("a",{attrs:{href:"https://github.com/Ezuy-Lee/BigDataComponents",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://github.com/Ezuy-Lee/BigDataComponents"),t("OutboundLink")],1)]),e._v(" "),t("h4",{attrs:{id:"_1-基本信息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-基本信息"}},[e._v("#")]),e._v(" 1. 基本信息")]),e._v(" "),t("p",[e._v("各个组件的版本信息如下（MySQL的 root 密码为 root）：")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",{staticStyle:{"text-align":"center"}},[e._v("组件")]),e._v(" "),t("th",{staticStyle:{"text-align":"center"}},[e._v("版本")])])]),e._v(" "),t("tbody",[t("tr",[t("td",{staticStyle:{"text-align":"center"}},[e._v("基础镜像")]),e._v(" "),t("td",{staticStyle:{"text-align":"center"}},[e._v("ubuntu:18.04")])]),e._v(" "),t("tr",[t("td",{staticStyle:{"text-align":"center"}},[e._v("Hadoop")]),e._v(" "),t("td",{staticStyle:{"text-align":"center"}},[e._v("3.1.3")])]),e._v(" "),t("tr",[t("td",{staticStyle:{"text-align":"center"}},[e._v("Spark")]),e._v(" "),t("td",{staticStyle:{"text-align":"center"}},[e._v("2.4.4")])]),e._v(" "),t("tr",[t("td",{staticStyle:{"text-align":"center"}},[e._v("Hive (on Tez)")]),e._v(" "),t("td",{staticStyle:{"text-align":"center"}},[e._v("3.1.2")])]),e._v(" "),t("tr",[t("td",{staticStyle:{"text-align":"center"}},[e._v("Tez")]),e._v(" "),t("td",{staticStyle:{"text-align":"center"}},[e._v("0.9.2")])]),e._v(" "),t("tr",[t("td",{staticStyle:{"text-align":"center"}},[e._v("Hue")]),e._v(" "),t("td",{staticStyle:{"text-align":"center"}},[e._v("4.5.0")])]),e._v(" "),t("tr",[t("td",{staticStyle:{"text-align":"center"}},[e._v("Flink")]),e._v(" "),t("td",{staticStyle:{"text-align":"center"}},[e._v("1.9.1")])]),e._v(" "),t("tr",[t("td",{staticStyle:{"text-align":"center"}},[e._v("Zookeeper")]),e._v(" "),t("td",{staticStyle:{"text-align":"center"}},[e._v("3.5.6")])]),e._v(" "),t("tr",[t("td",{staticStyle:{"text-align":"center"}},[e._v("Kafka")]),e._v(" "),t("td",{staticStyle:{"text-align":"center"}},[e._v("2.3.1")])]),e._v(" "),t("tr",[t("td",{staticStyle:{"text-align":"center"}},[e._v("MySQL")]),e._v(" "),t("td",{staticStyle:{"text-align":"center"}},[e._v("5.7")])])])]),e._v(" "),t("h4",{attrs:{id:"_2-启动说明"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-启动说明"}},[e._v("#")]),e._v(" 2. 启动说明")]),e._v(" "),t("p",[e._v("镜像已经推送到Docker Hub，直接执行如下命令应当会开始拉取镜像：")]),e._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("docker run -it -p 8088:8088 -p 8888:8888 -h bigdata iamabug1128/bdp bash\n")])]),e._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[e._v("1")]),t("br")])]),t("p",[e._v("或者 clone 本项目并执行 "),t("code",[e._v("run-bdp.sh")]),e._v(" 脚本。")]),e._v(" "),t("blockquote",[t("p",[e._v("8088 是 YARN 的 Web UI 端口，8888 是 Hue 的端口。")]),e._v(" "),t("p",[e._v("主机名必须指定为 bigdata。")])]),e._v(" "),t("p",[e._v("进入镜像后，启动所有组件的命令：")]),e._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("/run/entrypoint.sh\n")])]),e._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[e._v("1")]),t("br")])]),t("p",[e._v("或者，单独启动 Kafka：")]),e._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[e._v("/run/start_kafka.sh\n")])]),e._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[e._v("1")]),t("br")])]),t("p",[e._v("查看进程，确认所有进程都已经启动：")]),e._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[e._v("root@bigdata:/"),t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# jps")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token number"}},[e._v("1796")]),e._v(" ResourceManager\n"),t("span",{pre:!0,attrs:{class:"token number"}},[e._v("1316")]),e._v(" DataNode\n"),t("span",{pre:!0,attrs:{class:"token number"}},[e._v("2661")]),e._v(" RunJar\n"),t("span",{pre:!0,attrs:{class:"token number"}},[e._v("1205")]),e._v(" NameNode\n"),t("span",{pre:!0,attrs:{class:"token number"}},[e._v("2662")]),e._v(" RunJar\n"),t("span",{pre:!0,attrs:{class:"token number"}},[e._v("3719")]),e._v(" Jps\n"),t("span",{pre:!0,attrs:{class:"token number"}},[e._v("1914")]),e._v(" NodeManager\n"),t("span",{pre:!0,attrs:{class:"token number"}},[e._v("1530")]),e._v(" SecondaryNameNode\n"),t("span",{pre:!0,attrs:{class:"token number"}},[e._v("523")]),e._v(" QuorumPeerMain\n"),t("span",{pre:!0,attrs:{class:"token number"}},[e._v("543")]),e._v(" Kafka\n")])]),e._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[e._v("1")]),t("br"),t("span",{staticClass:"line-number"},[e._v("2")]),t("br"),t("span",{staticClass:"line-number"},[e._v("3")]),t("br"),t("span",{staticClass:"line-number"},[e._v("4")]),t("br"),t("span",{staticClass:"line-number"},[e._v("5")]),t("br"),t("span",{staticClass:"line-number"},[e._v("6")]),t("br"),t("span",{staticClass:"line-number"},[e._v("7")]),t("br"),t("span",{staticClass:"line-number"},[e._v("8")]),t("br"),t("span",{staticClass:"line-number"},[e._v("9")]),t("br"),t("span",{staticClass:"line-number"},[e._v("10")]),t("br"),t("span",{staticClass:"line-number"},[e._v("11")]),t("br")])]),t("p",[e._v("除了 Hue 安装在 "),t("code",[e._v("/usr/share/hue")]),e._v(" 、MySQL 安装在系统路径以外，其它所有的组件的安装在 "),t("code",[e._v("/usr/local/")]),e._v(" 目录下：")]),e._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[e._v("root@bigdata:/"),t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# ls /usr/local/      ")]),e._v("\nbin  etc  flink  games  hadoop  hive  include  kafka  lib  "),t("span",{pre:!0,attrs:{class:"token function"}},[e._v("man")]),e._v("  sbin  share  spark  src  tez  zookeeper\n")])]),e._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[e._v("1")]),t("br"),t("span",{staticClass:"line-number"},[e._v("2")]),t("br")])]),t("h4",{attrs:{id:"_3-使用示例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-使用示例"}},[e._v("#")]),e._v(" 3. 使用示例")]),e._v(" "),t("h5",{attrs:{id:"_3-1-使用-hue-上传文件到-hdfs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-使用-hue-上传文件到-hdfs"}},[e._v("#")]),e._v(" 3.1 使用 Hue 上传文件到 HDFS")]),e._v(" "),t("p",[e._v("访问 "),t("code",[e._v("localhost:8888")]),e._v(" ，输入 "),t("code",[e._v("admin, admin")]),e._v(" 登录 Hue，点击左侧 "),t("code",[e._v("Files")]),e._v(" 导航按钮，出现文件浏览器页面：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://tva1.sinaimg.cn/large/006tNbRwly1g9rj4l1p6jj32l60jqafp.jpg",alt:""}})]),e._v(" "),t("p",[e._v("点击右上角的 "),t("code",[e._v("Upload")]),e._v(" 按钮，选择一个文件上传，上传后页面：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://tva1.sinaimg.cn/large/006tNbRwly1g9rj9tqq8qj31fc0b83zp.jpg",alt:""}})]),e._v(" "),t("p",[e._v("回到容器的命令行中，查看 "),t("code",[e._v("/user/admin")]),e._v(" 目录：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://tva1.sinaimg.cn/large/006tNbRwly1g9rjbu571mj31dg08mn2d.jpg",alt:""}})]),e._v(" "),t("p",[e._v("说明上传确实成功了。")]),e._v(" "),t("h5",{attrs:{id:"_3-2-运行-flink-on-yarn-的-wordcount-例子"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-运行-flink-on-yarn-的-wordcount-例子"}},[e._v("#")]),e._v(" 3.2 运行 Flink on Yarn 的 WordCount 例子")]),e._v(" "),t("p",[e._v("在命令行中切换到 "),t("code",[e._v("/usr/local/flink")]),e._v(" 目录，执行 "),t("code",[e._v("./bin/flink run -m yarn-cluster -p 4 -yjm 1024m -ytm 4096m ./examples/batch/WordCount.jar")]),e._v("：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://tva1.sinaimg.cn/large/006tNbRwly1g9rjqylh15j32ia0qunpd.jpg",alt:""}})]),e._v(" "),t("p",[e._v("在浏览器中打开 "),t("code",[e._v("http://localhost:8088")]),e._v("，可以看到正在执行的 Flink 任务：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://tva1.sinaimg.cn/large/006tNbRwly1g9rjp3xjjoj327e0e2jv8.jpg",alt:""}})]),e._v(" "),t("p",[e._v("任务顺利完成：")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://tva1.sinaimg.cn/large/006tNbRwly1g9rjsiqu1qj318a0hagxq.jpg",alt:""}})]),e._v(" "),t("h4",{attrs:{id:"_4-构建说明"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-构建说明"}},[e._v("#")]),e._v(" 4. 构建说明")]),e._v(" "),t("p",[e._v("目录结构如下：")]),e._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[e._v("BigDataParty $ tree               \n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[e._v(".")]),e._v("\n├── Dockerfile\n├── README.md\n├── build.sh\n├── conf\n├── packages\n├── run-bdp.sh\n└── scripts\n")])]),e._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[e._v("1")]),t("br"),t("span",{staticClass:"line-number"},[e._v("2")]),t("br"),t("span",{staticClass:"line-number"},[e._v("3")]),t("br"),t("span",{staticClass:"line-number"},[e._v("4")]),t("br"),t("span",{staticClass:"line-number"},[e._v("5")]),t("br"),t("span",{staticClass:"line-number"},[e._v("6")]),t("br"),t("span",{staticClass:"line-number"},[e._v("7")]),t("br"),t("span",{staticClass:"line-number"},[e._v("8")]),t("br"),t("span",{staticClass:"line-number"},[e._v("9")]),t("br")])]),t("p",[e._v("除了 README 和 Dockerfile 各文件目录简介如下：")]),e._v(" "),t("ul",[t("li",[e._v("build.sh：下载各组件的压缩包并执行 "),t("code",[e._v("docker build")])]),e._v(" "),t("li",[e._v("run-bdp.sh：运行构建好的镜像，并暴露 Hue 和 Yarn 的 Web 端口")]),e._v(" "),t("li",[e._v("conf：存放各个组件的配置文件，构建镜像时拷贝到各组件的目录下")]),e._v(" "),t("li",[e._v("packages：存放各个组件的压缩包，构建镜像时解压到 "),t("code",[e._v("/usr/local")]),e._v(" 目录下")]),e._v(" "),t("li",[e._v("scripts：存放各个组件初始化和启动脚本，构建镜像时拷贝到 "),t("code",[e._v("/run")]),e._v(" 目录下")])]),e._v(" "),t("h4",{attrs:{id:"参考"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#参考"}},[e._v("#")]),e._v(" 参考")]),e._v(" "),t("ul",[t("li",[e._v("《Hadoop权威指南》")]),e._v(" "),t("li",[e._v("《架构解密-从分布式到微服务》")])])])}),[],!1,null,null,null);a.default=n.exports}}]);